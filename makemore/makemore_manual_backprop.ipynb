{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qJsnrG0oOMZ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G54bi8CO_i3z",
        "outputId": "d3151e6d-a074-4e99-940c-4e69bdb5d5d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-02 07:16:58--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-02 07:16:58 (6.14 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=open('names.txt','r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXojZZocOTDx",
        "outputId": "79d391c9-e44a-4a1e-bcb9-3506e78a0ba5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(''.join(words))))\n",
        "stoi={s:i+1  for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos={i:s for s,i in stoi.items()}\n",
        "vocab_size=len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ7xpja0OZyN",
        "outputId": "09cae1b5-aadb-4f98-aea4-3f65e225fe81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function we will use later when comparing manual gradients to Pytorch gradients\n",
        "\n",
        "def cmp(s,dt,t):\n",
        "  ex=torch.all(dt==t.grad).item()\n",
        "  app=torch.allclose(dt,t.grad)\n",
        "  maxdiff=(dt-t.grad).abs().max().item()\n",
        "  print(f'{s:15s} |  exact:{str(ex):5s} | Approximate:{str(app):5s} | maxdiff:{maxdiff}')"
      ],
      "metadata": {
        "id": "oje2NcnrBH23"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training split , dev/validation split , test split\n",
        "# 80% , 10% , 10%\n",
        "\n",
        "block_size=3 # context length , how many characters  do we take to predict the next one\n",
        "def build_dataset(words):\n",
        "  #build the dataset\n",
        "  X,Y = [],[]\n",
        "\n",
        "  for w in words:\n",
        "    context=block_size*[0]\n",
        "    for ch in w + \".\":\n",
        "      ix=stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "\n",
        "      context=context[1:]+[ix]\n",
        "\n",
        "  X=torch.tensor(X)\n",
        "  Y=torch.tensor(Y)\n",
        "\n",
        "  print(X.shape,Y.shape)\n",
        "  return X,Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "n1=int(0.8*len(words))\n",
        "n2=int(0.9*len(words))\n",
        "\n",
        "Xtr,Ytr=build_dataset(words[:n1])\n",
        "Xdev,Ydev=build_dataset(words[n1:n2])\n",
        "Xte,Yte=build_dataset(words[n2:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cg9EElwOc6O",
        "outputId": "cd9dd894-a934-4b19-b3cd-f020ce286aa7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182778, 3]) torch.Size([182778])\n",
            "torch.Size([22633, 3]) torch.Size([22633])\n",
            "torch.Size([22735, 3]) torch.Size([22735])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_embed=10 # the dimensionality of the character embedding vectors\n",
        "n_hidden=200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g=torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C=torch.randn((vocab_size,n_embed),generator=g)\n",
        "\n",
        "\n",
        "#Layer 1\n",
        "W1=torch.randn((n_embed*block_size,n_hidden),generator=g) * (5/3)/((n_embed*block_size)**0.5)\n",
        "b1=torch.randn(n_hidden,generator=g) * 0.1\n",
        "\n",
        "\n",
        "#Layer 2\n",
        "W2=torch.randn((n_hidden,vocab_size),generator=g) * 0.1\n",
        "b2=torch.randn(vocab_size , generator=g) * 0.1\n",
        "\n",
        "\n",
        "#BATCH NORM PARAMETERS\n",
        "\n",
        "bngain=torch.ones((1,n_hidden)) * 0.1 + 1.0\n",
        "bnbias=torch.zeros((1,n_hidden)) * 0.1\n",
        "\n",
        "\n",
        "bnmean_running=torch.zeros((1,n_hidden))\n",
        "bnstd_running=torch.ones((1,n_hidden))\n",
        "\n",
        "parameters=[C,W1,b1,W2,b2,bngain,bnbias]\n",
        "\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "  p.requires_grad=True\n"
      ],
      "metadata": {
        "id": "OwY5g-h1Oi4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01ea0a6-cc8b-46e6-c790-b0df08e40fa4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "n=batch_size # shorter variable for convenience\n",
        "\n",
        "ix=torch.randint(0,Xtr.shape[0],(batch_size,), generator=g)\n",
        "Xb, Yb= Xtr[ix], Ytr[ix]  #batch X,Y"
      ],
      "metadata": {
        "id": "-Zp3WCBp9Ecp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forward pass\n",
        "\n",
        "emb=C[Xb]  # embed the characters into vectors\n",
        "embcat=emb.view(emb.shape[0],-1) # concatenate the vectors\n",
        "\n",
        "#Linear layer 1\n",
        "hprebn=embcat@W1+b1 # hidden layer pre-activation\n",
        "\n",
        "#Batch Norm Layer\n",
        "bnmeani=(1/n)*hprebn.sum(0,keepdim=True)\n",
        "bndiff=hprebn-bnmeani\n",
        "bndiff2=bndiff**2\n",
        "bnvar=(1/(n-1))*(bndiff2).sum(0,keepdim=True)  #(note: Bessel's correction dividing by n-1 not n)\n",
        "bnvar_inv=(bnvar+1e-5)**(-0.5)\n",
        "bnraw=bndiff*bnvar_inv\n",
        "hpreact=bngain*bnraw+bnbias\n",
        "\n",
        "\n",
        "#Non-Linearity\n",
        "h=torch.tanh(hpreact) # hidden layer\n",
        "\n",
        "#Linear layer 2\n",
        "logits=h@W2+b2\n",
        "\n",
        "\n",
        "#Cross entropy (same as F.cross_entropy(logits,Yb))\n",
        "\n",
        "logit_maxes=logits.max(1,keepdim=True).values\n",
        "norm_logits=logits-logit_maxes  # subtract max for numerical stability\n",
        "counts=norm_logits.exp()\n",
        "counts_sum=counts.sum(1,keepdim=True)\n",
        "counts_sum_inv=counts_sum**(-1)\n",
        "probs=counts*counts_sum_inv\n",
        "\n",
        "logprobs=probs.log()\n",
        "loss=-logprobs[range(n),Yb].mean()\n",
        "\n",
        "\n",
        "#pytorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad=None\n",
        "\n",
        "\n",
        "for t in [logprobs,probs,counts,counts_sum,counts_sum_inv,norm_logits,\n",
        "          logit_maxes,logits,h,hpreact,bnraw,bnvar_inv,bnvar,bndiff2,bndiff,hprebn,\n",
        "          bnmeani,embcat,emb]:\n",
        "          t.retain_grad()\n",
        "\n",
        "\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fM7KqL19mM8",
        "outputId": "e58e444a-543a-4a2c-fee5-8f33aeda1cfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.1375, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bndiff.shape,hprebn.shape,bnmeani.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB4Rm4sbGEm0",
        "outputId": "51fc8c58-05c8-47b4-962d-12fefa9bdc19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts.shape,counts_sum_inv.shape, probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X7gEqNJH9ZN",
        "outputId": "5794f994-0a99-4db7-e1f3-825e6d8f38d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a11 a12 a13         b1\n",
        "a21 a22 a23 ---->   b2\n",
        "a31 a32 a33         b3\n",
        "\"\"\"\n",
        "logits.shape , logit_maxes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lW6-Wj2TE1v",
        "outputId": "77110173-58a3-44f6-d72b-edcef80c4170"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2.shape , h .shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42OocY53ZmzA",
        "outputId": "8a4a6d88-899d-4f3c-f5b0-d2be0227f054"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 27]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "c = a * b , but with tensors\n",
        "a[3*3] * b[3*1] --->\n",
        "a11*b1 , a12 * b1 , a13 * b1\n",
        "a21*b2 , a22 * b2 , a23 * b2\n",
        "a31*b3 , a32 * b3 , a33 * b3\n",
        "\n",
        "c[3*3]\n",
        "\n",
        "BROADCASTING OPERATION\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "HnqiThhfIAIZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb38712c-4f07-4ee4-d1a8-f3da9d57feea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nc = a * b , but with tensors\\na[3*3] * b[3*1] --->\\na11*b1 , a12 * b1 , a13 * b1\\na21*b2 , a22 * b2 , a23 * b2\\na31*b3 , a32 * b3 , a33 * b3\\n\\nc[3*3]\\n\\nBROADCASTING OPERATION\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape,C.shape,Xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbjTpuWKKGUy",
        "outputId": "8f26a476-7816-412a-cc03-b999986d9661"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape,embcat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZNZtIEHJQ4U",
        "outputId": "84d342e9-83a3-4901-fb78-de898631e849"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 10]), torch.Size([32, 30]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnraw.shape, bndiff.shape, bnvar_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYdCsrtMAf6J",
        "outputId": "f22144d7-0942-4af3-b3fc-1e82fc421ac5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(F.one_hot(logits.max(1).indices,num_classes=logits.shape[1]) )"
      ],
      "metadata": {
        "id": "1Ufw5Q7dVSKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "ebf1469b-f8ed-44d8-8c26-f636b28fd26d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d10b241d850>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "just for convenice writing dlogprobs as (dloss/dlogprobs)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        " loss = -(a+b+c)/3\n",
        "dloss/da=-(1/3)\n",
        "dloss/db=-(1/3)\n",
        "dloss/dc=-(1/3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "dloss/dprobs= (dloss/dlogprobs) * (dlogprobs*dprobs)\n",
        "\n",
        "dlogprobs= (1/probs) * dprobs\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "dlogprobs= torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n),Yb]=-1.0/n\n",
        "\n",
        "dprobs= dlogprobs * (1.0/probs)\n",
        "\n",
        "\n",
        "dcounts_sum_inv=(dprobs*counts).sum(1,keepdim=True)\n",
        "\n",
        "\n",
        "dcounts= dprobs*counts_sum_inv\n",
        "\n",
        "dcounts_sum= dcounts_sum_inv * -(counts_sum**-2)\n",
        "\n",
        "dcounts+=torch.ones_like(counts)*dcounts_sum\n",
        "\n",
        "dnorm_logits=(norm_logits).exp() * dcounts\n",
        "\n",
        "dlogits= 1.0 * dnorm_logits\n",
        "\n",
        "dlogit_maxes=(-1.0*dnorm_logits).sum(1,keepdim=True)\n",
        "\n",
        "dlogits+=F.one_hot(logits.max(1).indices,num_classes=logits.shape[1]) * dlogit_maxes\n",
        "\n",
        "dh=dlogits @ W2.T\n",
        "\n",
        "dW2= h.T @ dlogits\n",
        "\n",
        "db2= dlogits.sum(0)\n",
        "\n",
        "dhpreact= dh * (1.0- h**2)\n",
        "\n",
        "dbngain=(dhpreact*bnraw).sum(0,keepdim=True)\n",
        "dbnraw=dhpreact*bngain\n",
        "dbnbias=dhpreact.sum(0,keepdim=True)\n",
        "\n",
        "dbndiff=bnvar_inv*dbnraw\n",
        "\n",
        "dbnvar_inv=(bndiff*dbnraw).sum(0,keepdim=True)\n",
        "\n",
        "dbnvar=dbnvar_inv*(-0.5*(bnvar+1e-5)**(-1.5))\n",
        "\n",
        "\n",
        "dbndiff2=(1.0/(n-1))*torch.ones_like(bndiff2)*dbnvar\n",
        "\n",
        "dbndiff+=2*bndiff*dbndiff2\n",
        "\n",
        "dhprebn=dbndiff*1.0\n",
        "\n",
        "dbnmeani= (-1.0*dbndiff).sum(0,keepdim=True)\n",
        "\n",
        "dhprebn+=(1.0/n)*torch.ones_like(hprebn)*dbnmeani\n",
        "\n",
        "dembcat= dhprebn @ W1.T\n",
        "\n",
        "dW1= embcat.T @ dhprebn\n",
        "\n",
        "db1=dhprebn.sum(0)\n",
        "\n",
        "demb=dembcat.view(emb.shape)\n",
        "\n",
        "dC= torch.zeros_like(C)\n",
        "\n",
        "for i in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix=Xb[i,j]\n",
        "    dC[ix]+=demb[i,j]\n",
        "\n",
        "\n",
        "cmp('dlogprobs',dlogprobs,logprobs)\n",
        "cmp('dprobs',dprobs,probs)\n",
        "cmp('dcounts_sum_inv',dcounts_sum_inv,counts_sum_inv)\n",
        "cmp('dcounts_sum',dcounts_sum,counts_sum)\n",
        "cmp('dcounts',dcounts,counts)\n",
        "cmp('dnorm_logits',dnorm_logits,norm_logits)\n",
        "cmp('logit_maxes',dlogit_maxes,logit_maxes)\n",
        "cmp('logits',dlogits,logits)\n",
        "cmp('h',dh,h)\n",
        "cmp('W2',dW2,W2)\n",
        "cmp('b2',db2,b2)\n",
        "cmp('hpreact',dhpreact,hpreact)\n",
        "cmp('bnbias',dbnbias,bnbias)\n",
        "cmp('bngain',dbngain,bngain)\n",
        "cmp('bnraw',dbnraw,bnraw)\n",
        "cmp('bnvar_inv',dbnvar_inv,bnvar_inv)\n",
        "cmp('bnvar',dbnvar,bnvar)\n",
        "cmp('bndiff2',dbndiff2,bndiff2)\n",
        "cmp('bndiff',dbndiff,bndiff)\n",
        "cmp('bnmeani',dbnmeani,bnmeani)\n",
        "cmp('hprebn',dhprebn,hprebn)\n",
        "cmp('embcat',dembcat,embcat)\n",
        "cmp('W1',dW1,W1)\n",
        "cmp('b1',db1,b1)\n",
        "cmp('emb',demb,emb)\n",
        "cmp('C',dC,C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN7XJSKhA_-m",
        "outputId": "16b30f24-aba9-4a40-90b9-cbae349e5536"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogprobs       |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "dprobs          |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "dcounts_sum_inv |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "dcounts_sum     |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "dcounts         |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "dnorm_logits    |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "logit_maxes     |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "logits          |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "h               |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "W2              |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "b2              |  exact:True  | Approximate:True  | maxdiff:0.0\n",
            "hpreact         |  exact:False | Approximate:True  | maxdiff:9.313225746154785e-10\n",
            "bnbias          |  exact:False | Approximate:True  | maxdiff:7.450580596923828e-09\n",
            "bngain          |  exact:False | Approximate:True  | maxdiff:1.862645149230957e-09\n",
            "bnraw           |  exact:False | Approximate:True  | maxdiff:1.3969838619232178e-09\n",
            "bnvar_inv       |  exact:False | Approximate:True  | maxdiff:3.725290298461914e-09\n",
            "bnvar           |  exact:False | Approximate:True  | maxdiff:1.3969838619232178e-09\n",
            "bndiff2         |  exact:False | Approximate:True  | maxdiff:4.3655745685100555e-11\n",
            "bndiff          |  exact:False | Approximate:True  | maxdiff:1.3969838619232178e-09\n",
            "bnmeani         |  exact:False | Approximate:True  | maxdiff:3.725290298461914e-09\n",
            "hprebn          |  exact:False | Approximate:True  | maxdiff:1.3969838619232178e-09\n",
            "embcat          |  exact:False | Approximate:True  | maxdiff:3.725290298461914e-09\n",
            "W1              |  exact:False | Approximate:True  | maxdiff:7.450580596923828e-09\n",
            "b1              |  exact:False | Approximate:True  | maxdiff:3.841705620288849e-09\n",
            "emb             |  exact:False | Approximate:True  | maxdiff:3.725290298461914e-09\n",
            "C               |  exact:False | Approximate:True  | maxdiff:1.6763806343078613e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bngain.shape, bnraw.shape, dhpreact.shape , bnbias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjigb6n--ivH",
        "outputId": "1956b562-3fb6-4c96-a215-5516e36392f8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: backprop through cross_entropy but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the loss,\n",
        "# take the derivative, simplify the expression, and just write it out\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# now:\n",
        "loss_fast = F.cross_entropy(logits, Yb)\n",
        "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD1G3apn5IOO",
        "outputId": "0cb01c64-6e76-4662-c113-8b6a3712eff3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.137534141540527 diff: 4.76837158203125e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits=F.softmax(logits,1)\n",
        "dlogits[range(n),Yb]-=1\n",
        "dlogits/=n\n",
        "cmp('logits',dlogits,logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ResfaC2sCp",
        "outputId": "908609a6-0aa3-4a58-bd0b-7dd50870a77a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits          |  exact:False | Approximate:True  | maxdiff:5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape,Yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVOgI8pu4Szl",
        "outputId": "0b4557e8-a1a4-42c5-f2f0-0feca4166803"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(logits,1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbvFLIO4UO0",
        "outputId": "194417ca-b36c-4cde-9b77-806b35d2494e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0077, 0.0418, 0.0209, 0.0069, 0.1033, 0.0765, 0.1834, 0.0429, 0.0071,\n",
              "        0.0278, 0.0278, 0.0709, 0.0142, 0.0431, 0.0040, 0.0060, 0.0286, 0.0056,\n",
              "        0.0411, 0.0302, 0.0924, 0.0212, 0.0101, 0.0154, 0.0238, 0.0279, 0.0193],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yr9fhhn4WeZ",
        "outputId": "7ff547c4-50ae-4fa1-ee7e-f4fc976ab90a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0002,  0.0013,  0.0007,  0.0002,  0.0032,  0.0024,  0.0057,  0.0013,\n",
              "        -0.0310,  0.0009,  0.0009,  0.0022,  0.0004,  0.0013,  0.0001,  0.0002,\n",
              "         0.0009,  0.0002,  0.0013,  0.0009,  0.0029,  0.0007,  0.0003,  0.0005,\n",
              "         0.0007,  0.0009,  0.0006], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "sum is very close to zero , because kind of push/pull is happening, the correct probability is being pushed up\n",
        "while the incorrect probability is being pulled down. This is in effect affects the weights and biases of the network all the way down\n",
        "to the input layer\n",
        "\"\"\"\n",
        "\n",
        "dlogits[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2iERPbq4XHS",
        "outputId": "86e88311-5875-4f56-9031-8740b88ea691"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.3283e-09, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(dlogits.detach(),cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "T3aXYRYr3px3",
        "outputId": "b23526f1-d043-4563-ca64-430c9a13ad6c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d10b1b8d850>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: backprop through batchnorm but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
        "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
        "# BatchNorm paper: https://arxiv.org/abs/1502.03167\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# now:\n",
        "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
        "print('max diff:', (hpreact_fast - hpreact).abs().max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuvEHlCv5MHJ",
        "outputId": "e475993b-49c5-48ca-ea43-48f0f2212ace"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpuvybXR-8DR",
        "outputId": "b277e403-7f86-4858-92f5-e4f2ffce46e0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhpreact.shape,dhpreact.sum(0).shape,bnraw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzftVUkU9viw",
        "outputId": "8c3b5d8d-63ab-42a8-9d83-ada4df5d7d67"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bngain.shape,bnvar_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukf6YFfC-R3u",
        "outputId": "d670c00e-4ba2-4fa5-c28c-fab11ae6ab7c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# backward pass\n",
        "\n",
        "# before we had:\n",
        "# dbnraw = bngain * dhpreact\n",
        "# dbndiff = bnvar_inv * dbnraw\n",
        "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "# dbndiff += (2*bndiff) * dbndiff2\n",
        "# dhprebn = dbndiff.clone()\n",
        "# dbnmeani = (-dbndiff).sum(0)\n",
        "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
        "# (you'll also need to use some of the variables from the forward pass up above)\n",
        "\n",
        "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gdT8Xzo5M2g",
        "outputId": "3354124a-cfcd-402f-8e67-f8b14566ede2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          |  exact:False | Approximate:True  | maxdiff:1.3969838619232178e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: putting it all together!\n",
        "# Train the MLP neural net with your own backward pass\n",
        "\n",
        "# init\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(f'Number of Parameters:{sum(p.nelement() for p in parameters)}')\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size # convenience\n",
        "lossi = []\n",
        "\n",
        "# use this context manager for efficiency once your backward pass is written (TODO)\n",
        "with torch.no_grad():\n",
        "\n",
        "# kick off optimization\n",
        "  for i in range(max_steps):\n",
        "\n",
        "    # minibatch construct\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xb] # embed the characters into vectors\n",
        "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "    # Linear layer\n",
        "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "    # BatchNorm layer\n",
        "    # -------------------------------------------------------------\n",
        "    bnmean = hprebn.mean(0, keepdim=True)\n",
        "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
        "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "    hpreact = bngain * bnraw + bnbias\n",
        "    # -------------------------------------------------------------\n",
        "    # Non-linearity\n",
        "    h = torch.tanh(hpreact) # hidden layer\n",
        "    logits = h @ W2 + b2 # output layer\n",
        "    loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "      p.grad = None\n",
        "\n",
        "    # manual backprop!\n",
        "    dlogits=F.softmax(logits,1)\n",
        "    dlogits[range(n),Yb]-=1\n",
        "    dlogits/=n\n",
        "\n",
        "\n",
        "    # 2nd layer backprop\n",
        "    dh=dlogits @ W2.T\n",
        "    dW2= h.T @ dlogits\n",
        "\n",
        "    db2= dlogits.sum(0)\n",
        "\n",
        "    #tanh backprop\n",
        "    dhpreact= dh * (1.0- h**2)\n",
        "\n",
        "    #batchnorm backprop\n",
        "\n",
        "    dbngain=(dhpreact*bnraw).sum(0,keepdim=True)\n",
        "    dbnbias=dhpreact.sum(0,keepdim=True)\n",
        "\n",
        "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "\n",
        "    #1st layer\n",
        "    dembcat= dhprebn @ W1.T\n",
        "\n",
        "    dW1= embcat.T @ dhprebn\n",
        "\n",
        "    db1=dhprebn.sum(0)\n",
        "\n",
        "    #embedding\n",
        "    demb=dembcat.view(emb.shape)\n",
        "\n",
        "    dC= torch.zeros_like(C)\n",
        "\n",
        "    for k in range(Xb.shape[0]):\n",
        "      for j in range(Xb.shape[1]):\n",
        "        ix=Xb[k,j]\n",
        "        dC[ix]+=demb[k,j]\n",
        "    # -----------------\n",
        "\n",
        "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "\n",
        "    # -----------------\n",
        "    # update\n",
        "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "    for p, grad in zip(parameters, grads):\n",
        "      p.data+=-lr*grad\n",
        "      # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
        "      #p.data += -lr * grad # new way of swole doge TODO: enable\n",
        "\n",
        "    # track stats\n",
        "    if i % 10000 == 0: # print every once in a while\n",
        "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "    lossi.append(loss.log10().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98O6rMZb-ci2",
        "outputId": "7c6839d2-f505-4c1e-8203-8bcb66b6a33a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Parameters:12297\n",
            "      0/ 200000: 4.0807\n",
            "  10000/ 200000: 2.0957\n",
            "  20000/ 200000: 2.0667\n",
            "  30000/ 200000: 1.7591\n",
            "  40000/ 200000: 2.0495\n",
            "  50000/ 200000: 1.9422\n",
            "  60000/ 200000: 2.6276\n",
            "  70000/ 200000: 2.3350\n",
            "  80000/ 200000: 1.8153\n",
            "  90000/ 200000: 2.2998\n",
            " 100000/ 200000: 2.1586\n",
            " 110000/ 200000: 1.9169\n",
            " 120000/ 200000: 1.9188\n",
            " 130000/ 200000: 2.0760\n",
            " 140000/ 200000: 2.0601\n",
            " 150000/ 200000: 2.3629\n",
            " 160000/ 200000: 1.9903\n",
            " 170000/ 200000: 2.1860\n",
            " 180000/ 200000: 2.2385\n",
            " 190000/ 200000: 1.7978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ],
      "metadata": {
        "id": "gJjFLvIUD-NT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate train and val loss\n",
        "\n",
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QjEqDEYD-pP",
        "outputId": "5aa954a7-e348-4048-875e-eadee7b9cc8d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.0234570503234863\n",
            "val 2.32807993888855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # ------------\n",
        "      # forward pass:\n",
        "      # Embedding\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "      # ------------\n",
        "      # Sample\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvyrsypCEBB1",
        "outputId": "e268931f-9358-49a3-f4d3-99d5cdff7f20"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mora.\n",
            "mayah.\n",
            "see.\n",
            "madhayla.\n",
            "remman.\n",
            "emdrlee.\n",
            "adelynnelin.\n",
            "shi.\n",
            "jen.\n",
            "edelissopharleigh.\n",
            "malaia.\n",
            "nosalbergihi.\n",
            "jest.\n",
            "jaireth.\n",
            "konnie.\n",
            "casuma.\n",
            "ged.\n",
            "ryyah.\n",
            "faeh.\n",
            "yuma.\n"
          ]
        }
      ]
    }
  ]
}